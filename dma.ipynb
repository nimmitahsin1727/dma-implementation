{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMA - Scratch Implementation\n",
    "\n",
    "Here, I'm implementing the DMA model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOPoLTScu4V"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dma import DMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "N = 100  # number of documents\n",
    "V = 50  # vocabulary size\n",
    "K = 5  # number of topics\n",
    "\n",
    "# Generate document-topic distribution\n",
    "theta = np.random.dirichlet([0.5] * K, N)\n",
    "\n",
    "# Generate topic-word distribution\n",
    "phi = np.random.dirichlet([0.5] * V, K)\n",
    "\n",
    "# Generate documents\n",
    "X = np.zeros((N, V), dtype=int)\n",
    "for i in range(N):\n",
    "    z = np.random.choice(K, p=theta[i])\n",
    "    X[i] = np.random.multinomial(100, phi[z])\n",
    "\n",
    "# Fit DMA model\n",
    "alpha = 0.5\n",
    "beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma = DMA(K, alpha, beta)\n",
    "dma.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new document\n",
    "X_new = np.zeros((5, V), dtype=int)\n",
    "for i in range(5):\n",
    "    z = np.random.choice(K, p=theta[i])\n",
    "    X_new[i] = np.random.multinomial(100, phi[z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the topic distribution for the new document\n",
    "predicted_topics = dma.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Predicted Topic Distribution: [1.32269992e-175 1.56879766e-147 1.00000000e+000 2.65316137e-135\n",
      " 1.48498789e-115]\n",
      "Document 2 - Predicted Topic Distribution: [4.88275435e-078 1.83287752e-078 3.98570932e-086 4.70088113e-106\n",
      " 1.00000000e+000]\n",
      "Document 3 - Predicted Topic Distribution: [3.21519914e-169 2.17509076e-124 1.00000000e+000 9.11490836e-149\n",
      " 1.18314102e-091]\n",
      "Document 4 - Predicted Topic Distribution: [1.06264695e-085 3.47572747e-089 1.82573773e-085 1.16590233e-101\n",
      " 1.00000000e+000]\n",
      "Document 5 - Predicted Topic Distribution: [1.89812934e-151 1.09980934e-127 1.00000000e+000 8.97912522e-145\n",
      " 1.35943884e-089]\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted topic distribution for each document\n",
    "for i in range(5):\n",
    "    print(f\"Document {i+1} - Predicted Topic Distribution: {predicted_topics[i]}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UcOPoLTScu4V",
    "S_BBNjjzc4m5",
    "c0cAeBowGUVP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lda-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1669881b8e0ee381f1d44208a6e6b4675430ed382f288976bd9acdbb8db18405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
