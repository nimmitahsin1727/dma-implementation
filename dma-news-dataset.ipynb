{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMA - 20 news dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UcOPoLTScu4V"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from model.dma import DMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'rec.motorcycles', 'talk.politics.guns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 20 Newsgroups data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'rec.motorcycles', 'talk.politics.guns']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and convert documents to BoW representation\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to numpy array\n",
    "X_array = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20  # number of topics\n",
    "alpha = 0.5  # hyperparameter for the document-topic distribution\n",
    "beta = 0.5  # hyperparameter for the topic-word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dma = DMA(K, alpha, beta)\n",
    "dma.fit(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_test = vectorizer.fit_transform(newsgroups_test.data)\n",
    "\n",
    "X_test_array = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the DMA model to predict the topic distribution for each document\n",
    "p_z = dma.predict(X_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Predicted Topic Distribution: [4.73716037e-08 9.21917109e-14 8.66493314e-09 2.26567772e-03\n",
      " 6.48150632e-12 2.93040603e-04 4.25761813e-14 2.05599113e-12\n",
      " 1.13364233e-11 4.37270564e-01 2.14973847e-07 9.61023794e-05\n",
      " 6.08348688e-11 3.78674305e-07 4.67115553e-06 2.30218878e-05\n",
      " 8.53931992e-05 1.32929590e-08 3.55761753e-10 5.59960866e-01]\n",
      "Document 2 - Predicted Topic Distribution: [1.54423580e-02 9.99166468e-08 5.25416142e-04 1.73460251e-01\n",
      " 2.57384518e-06 2.22969493e-03 1.68949209e-08 3.64062203e-10\n",
      " 2.38281398e-05 8.02865286e-01 5.69197118e-06 1.66427661e-03\n",
      " 1.47480641e-06 1.10983340e-05 3.65675619e-05 6.05341211e-05\n",
      " 1.84304462e-03 9.17443543e-05 3.10003206e-06 1.73294285e-03]\n",
      "Document 3 - Predicted Topic Distribution: [3.62195611e-04 3.47178282e-10 6.06138862e-07 1.92066083e-03\n",
      " 2.88328994e-07 5.38469495e-10 6.70243425e-16 1.91898910e-13\n",
      " 7.23044183e-08 9.03752087e-02 2.27337418e-06 1.53911188e-05\n",
      " 1.45440890e-15 2.73664482e-04 7.02985474e-06 3.87751899e-06\n",
      " 2.05557678e-04 1.42220995e-08 5.95736358e-07 9.06832563e-01]\n",
      "Document 4 - Predicted Topic Distribution: [1.31360192e-01 4.57082204e-08 1.36195697e-05 7.63063933e-01\n",
      " 6.62446515e-06 3.83415606e-05 2.50331535e-09 1.34014616e-03\n",
      " 3.08164133e-06 5.51290541e-02 8.98541058e-03 1.97168681e-04\n",
      " 5.92444110e-06 3.73148980e-08 2.37166970e-02 1.63957213e-04\n",
      " 1.26977483e-02 7.84108511e-07 5.18437599e-04 2.75879441e-03]\n",
      "Document 5 - Predicted Topic Distribution: [0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05 0.05\n",
      " 0.05 0.05 0.05 0.05 0.05 0.05]\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted topic distribution for each document\n",
    "for i in range(5):\n",
    "    print(f\"Document {i+1} - Predicted Topic Distribution: {p_z[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, vocab, n_top_words):\n",
    "    for i, topic_dist in enumerate(model.phi):\n",
    "        topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "        print(f'Topic {i+1}: {\" \".join(topic_words)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: path patches devices second paste richard rates averages sale umich\n",
      "Topic 2: bindings kicked ridiculous locators green histograms wet east eddy nancy\n",
      "Topic 3: tom powerful pronounced lack machine vast login pounds holds alias\n",
      "Topic 4: mistake criminals thier riding lies enhancing haven street nancy lady\n",
      "Topic 5: stills risc stopped modeling leaves american pica screeching van white\n",
      "Topic 6: flow foot fool idea 212 ones 21 sect 205 line\n",
      "Topic 7: imported kbytes prove fucking improvements comparable van gov awful flying\n",
      "Topic 8: eddy pica locators kicked lack topic trained vice green martial\n",
      "Topic 9: gunners solved decisions 400 pay battle sessions uuencoded mar property\n",
      "Topic 10: tmp vice supplies tom court 000 siggraph distributed desert pavement\n",
      "Topic 11: bindings nurbs variable bios exchange model green recommend terry mac\n",
      "Topic 12: henry 22 6045 xx motorcyclists described 24th 144 49931 needless\n",
      "Topic 13: happen d8 happens coreldraw 000 searching foot pp hawk leaves\n",
      "Topic 14: entry flow generate quadra doors compiled armor flying viewers readers\n",
      "Topic 15: widespread countersteer lud raytrace cs sales grayscale ucbvax spyglass defending\n",
      "Topic 16: ears compiled looking naplps records mar body formed diamond com\n",
      "Topic 17: argument iowa 212 dedicated concept biological occasionally flee ears 153\n",
      "Topic 18: finished pica grn bds language consideration distributed cica giro warrant\n",
      "Topic 19: secure institutions constitution andy ethz convolution resistance grip sending instead\n",
      "Topic 20: sand owning intersection owners commit rr byu rw 4000 ttdddlib\n"
     ]
    }
   ],
   "source": [
    "display_topics(dma, vectorizer.get_feature_names_out(), n_top_words=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "UcOPoLTScu4V",
    "S_BBNjjzc4m5",
    "c0cAeBowGUVP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lda-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1669881b8e0ee381f1d44208a6e6b4675430ed382f288976bd9acdbb8db18405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
